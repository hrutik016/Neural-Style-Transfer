{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Style Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "from tensorflow.python.keras.applications.vgg19 import VGG19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG19(\n",
    "    include_top = False,\n",
    "    weights = 'imagenet'\n",
    ")\n",
    "\n",
    "model.trainable = False\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "from tensorflow.python.keras.models import Model\n",
    "\n",
    "from tensorflow.python.keras.applications.vgg19 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_image(image_path):\n",
    "    img = load_img(image_path)\n",
    "    img = img_to_array(img)\n",
    "    img = preprocess_input(img)\n",
    "    img = np.expand_dims(img, axis = 0)\n",
    "    return img\n",
    "\n",
    "\n",
    "def deprocess(x):\n",
    "    x[:, :, 0] += 103.939\n",
    "    x[:, :, 1] += 116.799\n",
    "    x[:, :, 2] += 123.456\n",
    "    \n",
    "    x = x[:, :,::-1]\n",
    "    \n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "\n",
    "def display_image(image):\n",
    "    if len(image.shape)==4:\n",
    "        img = np.squeeze(image, axis = 0)\n",
    "        \n",
    "    img = deprocess(img)\n",
    "    \n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(img)\n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(load_and_process_image('Style.jpg')) #Style Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(load_and_process_image('Content.jpg')) #Content Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_layer = 'block5_conv2'\n",
    "\n",
    "style_layers = [\n",
    "    'block1_conv1',\n",
    "    'block3_conv1',\n",
    "    'block5_conv1'\n",
    "]\n",
    "\n",
    "content_model = Model(\n",
    "    inputs = model.input,\n",
    "    outputs = model.get_layer(content_layer).output\n",
    ")\n",
    "\n",
    "style_models = [Model(inputs = model.input,\n",
    "                    outputs = model.get_layer(layer).output) for layer in style_layers]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_cost(content, generated):\n",
    "    a_C = content_model(content)\n",
    "    a_G = content_model(generated)\n",
    "    cost = tf.reduce_mean(tf.square(a_C - a_G))\n",
    "    return cost "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gram Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(A):\n",
    "    n_C = int(A.shape[-1])\n",
    "    a = tf.reshape(A, [-1, n_C])\n",
    "    n = tf.shape(a)[0]\n",
    "    G = tf.matmul(a, a, transpose_a = True)\n",
    "    return G/tf.cast(n, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = 1./len(style_models)\n",
    "\n",
    "def style_cost(style, generated):\n",
    "    J_style = 0\n",
    "    \n",
    "    for style_model in style_models:\n",
    "        a_S = style_model(style)\n",
    "        a_G = style_model(generated)\n",
    "        GS = gram_matrix(a_S)\n",
    "        GG = gram_matrix(a_G)\n",
    "        \n",
    "        current_cost = tf.reduce_mean(tf.square(GS - GG))\n",
    "        J_style += current_cost * lam\n",
    "    \n",
    "    return J_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "generated_images = [] \n",
    "\n",
    "def training_loop(content_path, style_path, iterations = 50,\n",
    "                 alpha = 10., beta = 20.):\n",
    "    \n",
    "    content = load_and_process_image(content_path)\n",
    "    \n",
    "    style = load_and_process_image(style_path)\n",
    "    \n",
    "    generated = tf.Variable(content, dtype = tf.float32)\n",
    "    \n",
    "    opt = tf.optimizers.Adam(learning_rate = 5.)\n",
    "    \n",
    "    best_cost = 1e12 + 0.1\n",
    "    best_image = None\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        with tf.GradientTape() as tape:\n",
    "            J_content = content_cost(content, generated)\n",
    "            J_style = style_cost(style, generated)\n",
    "            J_total = (alpha * J_content) + (beta * J_style)\n",
    "            \n",
    "        grads = tape.gradient(J_total, generated)\n",
    "        opt.apply_gradients([(grads, generated)])\n",
    "        \n",
    "        if J_total < best_cost:\n",
    "            best_cost = J_total\n",
    "            best_image = generated.numpy()\n",
    "            \n",
    "        print('Cost at {}: {}. Time elapsed: {}'.format(i, J_total, time.time() - start_time))\n",
    "        generated_images.append(generated.numpy())\n",
    "        \n",
    "    return best_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_image = training_loop('Content.jpg','Style.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(best_image) # Generated Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "\n",
    "for i in range(50):\n",
    "    plt.subplot(10, 5, i+1)\n",
    "    display_image(generated_images[i])\n",
    "    \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
